---
author: "Daniel Weinberger"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Brazil example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
params:
  sensitivity: TRUE
  crossval: FALSE
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.height = 3,
  fig.width = 5,
  fig.align = "center", 
  dpi=300, 
	out.width="600px"
)
```

---

```{r setup_packages, include=FALSE, echo=TRUE}
##THE FIRST TIME YOU USE THE PACKAGE, RUN THE FOLLOWING CODE
#install.packages('devtools') 
#library(devtools) 

#YOU WILL NEED TO MANUALLY SELECT A NUMBER AFTER RUNNIN THE FOLLOWING LINE TO INDICATE WHETHER YOU WANT TO UPDATE PACKAGES
#devtools::install_github('https://github.com/weinbergerlab/InterventionEvaluatR') 

library(xtable)
library(knitr)
library(InterventionEvaluatR)
```

---
title: "Estimated change associated with the introduction of vaccine in Brazil"
---

---
## View dataset
We are using a dataset that has several different age groups. These represent monthly time series for a number of different diseases. The columns have counts per month of hospitalizations for the causes indicated by the range of ICD10 codes indicated in the header name. 

For instance J12_18 has the nuber of hospitalizations that had ICD10 codes in the range J12-J18 during that month in the indicated age group.  We also will subset the data (just take age groups 8 and 9. It is also *very* important to sort the data by age group and date.

Here we load the data and do some minor pre-processing to subset the dataset. We will just keep age group 9 (<12 month old kids) and age group 8 (80+ year old adults)

```{r viewdata, include=TRUE}
    data(pnas_brazil, package = "InterventionEvaluatR") #load the data
    head(pnas_brazil[,1:5]) #View first few rows and columns
```

Ensure your date variable is in an R date format. If your variable is in a character or factor format, you need to tell R the format. 
-- %m is a 2 digit month; %b is a month abbreviation (ie Jan, Feb)
-- %d is a 2 digit day (0-31), 
-- %Y is a 4 digit year (e.g. 2011), %y is a 2 digit year (e.g. 11).  
These codes are separated by a dash or slash or space. Modify the tryFormats script below if needed to match the format in your dataset
```{r}

pnas_brazil$date<-as.Date(pnas_brazil$date, tryFormats=c('%Y-%m-%d',
                                                    '%m-%d-%Y',
                                                    '%m/%d/%Y',
                                                    '%Y/%m/%d',
                                                    '%d/%m/%Y'
                                                    ) )
```

Subset the dataset; restricting to age group 9 (<12m old kids) and date after Jan 1 2004.
```{r}
    pnas_brazil2<-pnas_brazil[pnas_brazil$age_group %in% c(9),] #Subset to age groups 8 and 9
    pnas_brazil2<-pnas_brazil2[order(pnas_brazil2$age_group, pnas_brazil2$date),] #Sort data by age group and month
    pnas_brazil2<-pnas_brazil2[as.Date(pnas_brazil2$date)>=as.Date('2004-01-01'),] #Ignore 2003
```

## Set parameters for analysis

Here we need to set a few parameters. We Use the evaluatr.init() function to specify the name of the dataset, the date at which the vaccine is introduced, the date at which we want to begin evaluating the vaccine (typically 1-2 year after vaccine introduction). We also provide some information on the dataset, sch as whether the data are monthly or quarterly (n_seasons), the variable names for the grouping variable, the date variable, the outcome variable, and the denominator variable (if any).

```{r setup_data, echo=TRUE}

analysis <- evaluatr.init(
  country = "Brazil", data = pnas_brazil2,
  post_period_start = "2010-01-01", #First 'post-intervention' month is Jan 2012
  eval_period_start = "2012-01-01", #We ignore first 2 years of data to allow for vaccine ramp up
  eval_period_end = "2013-12-01", #The evaluation period lasts 2 years
  n_seasons = 12, #This is monthly data, so select 12
  year_def = "cal_year", # we are in southern hemisphere, so aggregate results by calendar year (Jan-Dec)
  group_name = "age_group",  #Strata categry name
  date_name = "date", #Date variable name
  outcome_name = "J12_18", #Outcome variable name
  denom_name = "ach_noj" #Denominator variable name
)
set.seed(1)
```

## Run a simple analysis controlling for 1 control variable at a time

Before getting into more complicated analyses, we will first try to fit a simple Poisson regression model (with overdispersion) where we adjust for seasonality and 1 control variable at a time. this allows us to see how the use of different controls influences the results

The results are ordered by goodness of fit (based on AIC scores), with best fitting covariates on top.
```{r univariate, fig.width=3, fig.height=5}
 glmer_results= evaluatr.univariate(analysis)
 lapply(glmer_results,evaluatr.univariate.plot)
```



## Run the main analysis
Save the results in object 'impact_results'
```{r main analysis, include = FALSE}
impact_results = evaluatr.impact(analysis)
```

##Run sensitivity analyses
Sequentially drop the top 1,2, or 3 variables in synthetic controls analysis
```{r sensitivity_analyses, include = FALSE}
if (params$sensitivity) {
  sensitivity_results <- evaluatr.sensitivity(analysis)
}
```


#`r params$country` Results


```{r sparse, results="asis"}
if (!is.null(names(analysis$sparse_groups[analysis$sparse_groups])) && length(names(analysis$sparse_groups[analysis$sparse_groups])) != 0) {
  print(xtable(data.frame("Sparse Groups" = names(analysis$sparse_groups[analysis$sparse_groups]), check.names = FALSE), align = "cc"), type="html")
}
```

##combine estimates
```{r Comparison of estimates from different models, results="asis"}
if (params$crossval) {
  print(xtable(cbind.data.frame(crossval_results$rr_mean_stack_intervals, impact_results$full$rr_mean_intervals, impact_results$time$rr_mean_intervals, impact_results$time_no_offset$rr_mean_intervals, impact_results$its$rr_mean_intervals, impact_results$pca$rr_mean_intervals), align = "ccccccc"), type="html")
} else {
  print(xtable(cbind.data.frame(impact_results$best$rr_mean_intervals, impact_results$full$rr_mean_intervals, impact_results$time$rr_mean_intervals, impact_results$time_no_offset$rr_mean_intervals, impact_results$its$rr_mean_intervals, impact_results$pca$rr_mean_intervals), align = "ccccccc"), type="html")
}
```


##Cases averted
How many cases were prevented from the time of vaccine introduction to the last time point in each stratum (+/- 95% CrI)? You can modify the number 'last.point' to pull out the cumulative number of cases at any point in the time series
```{r}
last.point<-dim(impact_results$best$cumsum_prevented)[1]
cum.prevented<-impact_results$best$cumsum_prevented[last.point,,]
print(cum.prevented)
```


##Plot of Rate ratios, with size proportional to cross validation weights
```{r mainplot1, echo=FALSE}
plots <- evaluatr.plots(analysis)
plots$summary
```

##Number of variables selected in SC analysis
```{r modelsize, results="asis"}
model_size = data.frame(t(analysis$model_size))
print(xtable(setNames(model_size, c("Model Size")), align=rep("c", ncol(model_size) + 1)), type="html")
```

##Inclusion Probabilities
```{r incl, include = FALSE}
incl_probs <- NULL
for (group in analysis$groups) {
  incl_prob <- impact_results$full$groups[[group]]$inclusion_probs[-c(1:(analysis$n_seasons - 1)), ]
  incl_prob <- incl_prob[order(-incl_prob$inclusion_probs), ]
  incl_prob <- incl_prob[c(1:3), ]
  incl_prob2 <- incl_prob[, 2]
  incl_prob_names <- incl_prob[, 1]
  incl_prob3 <- data.frame("Group" = group, "Greatest Inclusion Variable" = incl_prob_names[1], "Greatest Inclusion Probability" = incl_prob2[1], "Second Greatest Inclusion Variable" = incl_prob_names[2], "Second Greatest Inclusion Probability" = incl_prob2[2], "Third Greatest Inclusion Variable" = incl_prob_names[3], "Third Greatest Inclusion Probability" = incl_prob2[3], check.names = FALSE)
  incl_probs <- rbind(incl_probs, incl_prob3)
}
rownames(incl_probs) <- NULL
```

```{r incl_table, results="asis"}
print(xtable(incl_probs, align = rep("c", ncol(incl_probs) + 1)), type="html")
```

## Weight Sensitivity Analysis
```{r sensitivity, results="asis"}
if (exists("sensitivity_results")) {
  print(xtable(sensitivity_results$sensitivity_table_intervals, align = rep("c", ncol(sensitivity_results$sensitivity_table_intervals) + 1)), type="html")
}
```


## Plot Observed vs expected monthly time series
```{r plots, results = 'asis', fig.width=5, fig.height=4}
for (group in names(plots$groups)) {
      par(mfrow=c(4,1))
      print(plots$groups[[group]]$pred_full )
      print(plots$groups[[group]]$pred_best )
      print(plots$groups[[group]]$pred_time )
      print(plots$groups[[group]]$pred_pca )
}
```

## Plot Observed vs expected yearly time series
```{r plots2, results = 'asis', fig.width=5, fig.height=4}
for (group in names(plots$groups)) {
      par(mfrow=c(4,1))
      print(plots$groups[[group]]$pred_full_agg )
      print(plots$groups[[group]]$pred_best_agg )
      print(plots$groups[[group]]$pred_time_agg )
      print(plots$groups[[group]]$pred_pca_agg )
}
```

## Plot cumulative cases prevented
Estimated using the 'best' model, between SC and STL+PCA

```{r plots3, results = 'asis', fig.width=5, fig.height=4}
for (group in names(plots$groups)) {
      par(mfrow=c(4,1))
      print(plots$groups[[group]]$cumsum_prevented )
}
```


### Use HDI intervals instead
The package calcuates both an equal-tail 95% credible interval and a 95% highest posterior density interval (HPD or HDI interval). The latter might be more appropriate when the posterior distribution is skewed. The objects with HDI intervals are saved with an appendix of 'HDI' so impact_results$best$pred_quantiles gives the estimate for equal tail intervals while impact_results$best$pred_quantiles_HDI gives the estimate for the HDI interval
impact_results$best$cumsum_prevented_hdi gives the estimate of cumulative cases prevented using HPI
ann_pred_HDI gives the annual predicted cases with HDI intervals
rr_mean_HDI gives the overall rate ratio caclulated with HDI

Here we compare the version calculated with equal-tailed intervals with HPD intervals. In this example they give very similar coverage
```{r}
impact_results$best$rr_mean
impact_results$best$rr_mean_hdi

```
Compare pointwise coverage of the 95% CrI calculated as HDI or equal-tailed
```{r}
matplot(impact_results$best$pred_quantiles_HDI[,,1], type='l', col='gray', lty=c(2,1,2), bty='l', ylim=c(0, max(impact_results$best$pred_quantiles_HDI[,,1])), ylab='Count')
matplot(impact_results$best$pred_quantiles[,,1], type='l', col='red', lty=c(2,1,2), bty='l', ylim=c(0, max(impact_results$best$pred_quantiles_HDI[,,1])), ylab='Count', add=T)
points(analysis$input_data[, analysis$outcome_name])
```

## Print results
```{r save_results, echo=FALSE}
output_file <- "Results" # Directory where results will be saved.
output_file <- paste0(output_file, "_", analysis$country, "_", format(Sys.time(), "%Y-%m-%d-%H%M%S"), ".Rds")
evaluatr.save(analysis, output_file)
```
